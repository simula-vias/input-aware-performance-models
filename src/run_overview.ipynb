{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from common import load_data, split_data\n",
    "import supervised\n",
    "import active\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import os.path as osp\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "output_dir = \"run_results\"\n",
    "dataset_sizes = [None, 1, 5, 0.01, 0.1, 0.25, 0.5, 0.75]\n",
    "selection_methods = [\"random\", \"kmeans\", \"submodular\"]\n",
    "learning_methods = supervised.methods\n",
    "random_seeds = [i*100 for i in range(1, 6)]\n",
    "tune_settings = [False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = load_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc\n",
      "gcc num. inputs {1, 3, 5, 7, None, 14, 21} num. configs {1, 36, 5, 8, None, 18, 54}\n",
      "gcc Missing 95 runs\n",
      "imagemagick\n",
      "imagemagick num. inputs {1, 225, 450, 675, 5, 9, None, 90} num. configs {1, 68, 5, 9, 45, None, 23}\n",
      "imagemagick Missing 4096 runs\n",
      "lingeling\n",
      "lingeling num. inputs {32, 1, 4, 5, 237, None, 79, 158} num. configs {1, 68, 5, 9, 45, None, 23}\n",
      "lingeling Missing 275 runs\n",
      "nodejs\n",
      "nodejs num. inputs {1, 5, 869, 174, None, 18, 435, 1304} num. configs {1, 34, 5, 12, None, 23}\n",
      "nodejs Missing 1624 runs\n",
      "poppler\n",
      "poppler num. inputs {1, 5, 134, 999, 333, None, 14, 666} num. configs {1, 2, 4, 5, 7, 11, None}\n",
      "poppler Missing 16360 runs\n",
      "sqlite\n",
      "sqlite num. inputs {1, 2, 34, 68, 5, 102, None, 14} num. configs {1, 2, 4, 5, 6, None}\n",
      "sqlite Missing 7545 runs\n",
      "x264\n",
      "x264 num. inputs {1, 290, 579, 5, 869, 12, None, 116} num. configs {1, 2, 5, 135, 45, None, 18, 90}\n",
      "x264 Missing 4765 runs\n",
      "xz\n",
      "xz num. inputs {1, 33, 5, 11, None, 22} num. configs {1, 3, 5, 7, None, 14, 21}\n",
      "xz Missing 64 runs\n",
      "Missing in total 34824 runs\n"
     ]
    }
   ],
   "source": [
    "systems = list(full_data[\"performance_properties\"].keys())\n",
    "inputs_feat_cols = full_data[\"feature_columns\"]\n",
    "data = full_data[\"data\"]\n",
    "commands_per_system = dict()\n",
    "for s in systems:\n",
    "    print(s)\n",
    "    num_inputs = full_data[\"input_counts\"][s]\n",
    "    num_configs = len(\n",
    "        pd.concat(\n",
    "            (data[s, i][inputs_feat_cols[s]] for i in range(num_inputs))\n",
    "        ).drop_duplicates()\n",
    "    )\n",
    "\n",
    "    avail_inputs = int(num_inputs * 0.9)\n",
    "    avail_configs = int(num_configs * 0.9)\n",
    "\n",
    "    selected_inputs = set(\n",
    "        [\n",
    "            math.ceil(avail_inputs * ds) if isinstance(ds, float) else ds\n",
    "            for ds in dataset_sizes\n",
    "        ]\n",
    "    )\n",
    "    selected_configs = set(\n",
    "        [\n",
    "            math.ceil(avail_configs * ds) if isinstance(ds, float) else ds\n",
    "            for ds in dataset_sizes\n",
    "        ]\n",
    "    )\n",
    "    print(s, \"num. inputs\", selected_inputs, \"num. configs\", selected_configs)\n",
    "    # This should confirm the numbers, but adds ~2 minutes to execution\n",
    "    # _, _, train_inp, train_cfg = split_data(data, s, full_data[\"input_counts\"], inputs_feat_cols, 1)\n",
    "    # print(f\"{s}\\t{avail_inputs}\\t{avail_configs}\\t{len(train_inp)}\\t{len(train_cfg)}\")\n",
    "    performance_properties = full_data[\"performance_properties\"][s]\n",
    "    run_name = f\"sl_{s}\"\n",
    "\n",
    "    commands_per_system[s] = []\n",
    "\n",
    "    for seed, method, num_inp, num_cfg, sel_inp, sel_cfg, perf_property, tune in itertools.product(\n",
    "        random_seeds,\n",
    "        learning_methods,\n",
    "        selected_inputs,\n",
    "        selected_configs,\n",
    "        selection_methods,\n",
    "        selection_methods,\n",
    "        performance_properties,\n",
    "        tune_settings\n",
    "    ):\n",
    "        if method == \"automl\":\n",
    "            continue\n",
    "\n",
    "        if num_inp is None and sel_inp != \"kmeans\":\n",
    "            continue\n",
    "\n",
    "        if num_cfg is None and sel_cfg != \"kmeans\":\n",
    "            continue\n",
    "\n",
    "        if num_cfg == 1 and num_inp == 1:\n",
    "            continue\n",
    "\n",
    "        identifier = supervised.get_identifier(\n",
    "            run_name=run_name,\n",
    "            system=s,\n",
    "            method=method,\n",
    "            num_inputs=num_inp,\n",
    "            input_selection=sel_inp,\n",
    "            num_configs=num_cfg,\n",
    "            config_selection=sel_cfg,\n",
    "            performance_property=perf_property,\n",
    "            seed=seed,\n",
    "            tune=tune,\n",
    "        )\n",
    "\n",
    "        if osp.exists(osp.join(\"..\", output_dir, identifier, \"eval_metrics.json\")):\n",
    "            # Run already completed\n",
    "            continue\n",
    "        \n",
    "        if num_inp is not None:\n",
    "            ni = f\"-ni {num_inp} -is {sel_inp}\"\n",
    "        else:\n",
    "            ni = \"\"\n",
    "\n",
    "        if num_cfg is not None:\n",
    "            nc = f\"-nc {num_cfg} -cs {sel_cfg}\"\n",
    "        else:\n",
    "            nc = \"\"\n",
    "\n",
    "        commands_per_system[s].append(\n",
    "            f\"python src/supervised.py {run_name} {s} {method} -o {output_dir} -pp {perf_property} {ni} {nc} --seed {seed}\"\n",
    "        )\n",
    "\n",
    "    print(f\"{s} Missing {len(commands_per_system[s])} runs\")\n",
    "\n",
    "total_runs_missing = sum([len(cmds) for cmds in commands_per_system.values()])\n",
    "print(f\"Missing in total {total_runs_missing} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../sl_run_commands.sh\", \"w\") as f:\n",
    "    for cmds in commands_per_system.values():\n",
    "        f.writelines(\"\\n\".join(cmds))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc\n",
      "gcc Missing 135 runs\n",
      "imagemagick\n",
      "imagemagick Missing 90 runs\n",
      "lingeling\n",
      "lingeling Missing 135 runs\n",
      "nodejs\n",
      "nodejs Missing 45 runs\n",
      "poppler\n",
      "poppler Missing 90 runs\n",
      "sqlite\n",
      "sqlite Missing 675 runs\n",
      "x264\n",
      "x264 Missing 225 runs\n",
      "xz\n",
      "xz Missing 90 runs\n",
      "Missing in total 1485 runs\n"
     ]
    }
   ],
   "source": [
    "systems = list(full_data[\"performance_properties\"].keys())\n",
    "inputs_feat_cols = full_data[\"feature_columns\"]\n",
    "data = full_data[\"data\"]\n",
    "commands_per_system = dict()\n",
    "learning_methods = active.methods\n",
    "strategies = active.query_strategies\n",
    "for s in systems:\n",
    "    print(s)\n",
    "    # This should confirm the numbers, but adds ~2 minutes to execution\n",
    "    # _, _, train_inp, train_cfg = split_data(data, s, full_data[\"input_counts\"], inputs_feat_cols, 1)\n",
    "    # print(f\"{s}\\t{avail_inputs}\\t{avail_configs}\\t{len(train_inp)}\\t{len(train_cfg)}\")\n",
    "    performance_properties = full_data[\"performance_properties\"][s]\n",
    "    run_name = f\"al_{s}\"\n",
    "\n",
    "    commands_per_system[s] = []\n",
    "\n",
    "    for seed, method, query_strat, perf_property, tune in itertools.product(\n",
    "        random_seeds[:3],\n",
    "        learning_methods,\n",
    "        strategies,\n",
    "        performance_properties,\n",
    "        tune_settings\n",
    "    ):\n",
    "        identifier = active.get_identifier(\n",
    "            run_name=run_name,\n",
    "            system=s,\n",
    "            method=method,\n",
    "            query_strategy=query_strat,\n",
    "            performance_property=perf_property,\n",
    "            seed=seed,\n",
    "            tune=tune,\n",
    "        )\n",
    "\n",
    "        if osp.exists(osp.join(output_dir, identifier, \"eval_metrics.json\")):\n",
    "            # Run already completed\n",
    "            continue\n",
    "        \n",
    "\n",
    "        commands_per_system[s].append(\n",
    "            f\"python src/active.py {run_name} {s} {method} -s {query_strat} -o {output_dir} -pp {perf_property} --seed {seed}\"\n",
    "        )\n",
    "\n",
    "    print(f\"{s} Missing {len(commands_per_system[s])} runs\")\n",
    "\n",
    "total_runs_missing = sum([len(cmds) for cmds in commands_per_system.values()])\n",
    "print(f\"Missing in total {total_runs_missing} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../al_run_commands.sh\", \"w\") as f:\n",
    "    for cmds in commands_per_system.values():\n",
    "        f.writelines(\"\\n\".join(cmds))\n",
    "        f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2aee31dfc3a5f20bb1d01fbb0c1246518aac1c647f3a11d2243eb9db17473a91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
